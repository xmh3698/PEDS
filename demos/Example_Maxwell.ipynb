{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEDS example: Maxwell surrogate\n",
    "\n",
    "This example of PEDS shows how to use the code from: *Pestourie, Raphaël, et al. \"Physics-enhanced deep surrogates for PDEs.\"*  In this example notebook, we illustrate PEDS for the surrogate of the diffusion equation's flux where the approximate solver is a coarse diffusion equation's solver. For this example, the input is the width of 10 layers of holes and the one-hot-encoding of three frequencies.\n",
    "    \n",
    "## Note on implementation\n",
    "\n",
    "In this notebook, we run the training on a single processor and J=1.\n",
    "\n",
    "However, the implementation of this code is meant to be parallel on multiple processors, where the element of a batch is computed in parallel over J groups of CPUs (J is the number models in the ensemble). For example, with a julia file `train_PEDS.jl`containing functions calls similart to the code in the cells below, the command to run large-scale training on a cluster would be:\n",
    "    \n",
    "`mpiexec -n 320 julia train_PEDS.jl` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mPackage cuDNN not found in current path.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- Run `import Pkg; Pkg.add(\"cuDNN\")` to install the cuDNN package, then restart julia.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- If cuDNN is not installed, some Flux functionalities will not be available when running on the GPU.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ FluxCUDAExt C:\\Users\\XMhua\\.julia\\packages\\Flux\\CUn7U\\ext\\FluxCUDAExt\\FluxCUDAExt.jl:57\u001b[39m\n",
      "WARNING: method definition for rrule at D:\\GT\\bugfix\\PEDS\\src\\coarse.jl:326 declares type variable N but does not use it.\n",
      "WARNING: method definition for rrule at D:\\GT\\bugfix\\PEDS\\src\\coarse.jl:326 declares type variable T but does not use it.\n",
      "WARNING: method definition for #rrule#33 at D:\\GT\\bugfix\\PEDS\\src\\coarse.jl:346 declares type variable N but does not use it.\n",
      "WARNING: method definition for #rrule#33 at D:\\GT\\bugfix\\PEDS\\src\\coarse.jl:346 declares type variable T but does not use it.\n",
      "WARNING: method definition for #realtransmissionSolver#35 at D:\\GT\\bugfix\\PEDS\\src\\coarse.jl:374 declares type variable N but does not use it.\n",
      "WARNING: method definition for #realtransmissionSolver#35 at D:\\GT\\bugfix\\PEDS\\src\\coarse.jl:374 declares type variable T but does not use it.\n",
      "WARNING: method definition for #rrule#36 at D:\\GT\\bugfix\\PEDS\\src\\coarse.jl:377 declares type variable N but does not use it.\n",
      "WARNING: method definition for #rrule#36 at D:\\GT\\bugfix\\PEDS\\src\\coarse.jl:377 declares type variable T but does not use it.\n",
      "WARNING: method definition for #imagtransmissionSolver#37 at D:\\GT\\bugfix\\PEDS\\src\\coarse.jl:378 declares type variable N but does not use it.\n",
      "WARNING: method definition for #imagtransmissionSolver#37 at D:\\GT\\bugfix\\PEDS\\src\\coarse.jl:378 declares type variable T but does not use it.\n",
      "WARNING: method definition for #rrule#38 at D:\\GT\\bugfix\\PEDS\\src\\coarse.jl:381 declares type variable N but does not use it.\n",
      "WARNING: method definition for #rrule#38 at D:\\GT\\bugfix\\PEDS\\src\\coarse.jl:381 declares type variable T but does not use it.\n"
     ]
    }
   ],
   "source": [
    "##load module\n",
    "include(\"../src/PEDS.jl\")\n",
    "\n",
    "##loading data\n",
    "X = readdlm(\"../data/X_maxwell10_small.csv\", ',')\n",
    "y = parse.(Complex{Float64}, readdlm(\"../data/y_maxwell10_small.csv\", ',')[:])\n",
    "\n",
    "Xv = X[:, 1:1024] #valid set\n",
    "Xtest = X[:, end-1023:end] #test set\n",
    "Xt = X[:, 1025:end]\n",
    "\n",
    "yv = y[1:1024] #valid set\n",
    "ytest = y[end-1023:end] #test set\n",
    "yt = y[1025:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalimitvalid = 2^10\n",
    "Jval=1\n",
    "batchsize=64\n",
    "\n",
    "##Definition of problem constants\n",
    "const debug = false\n",
    "const drv = DataRunner(Xv, yv, [1]);\n",
    "const al = ALstruct(J=Jval, Nvalid=datalimitvalid, batchsize=batchsize);\n",
    "const valid = initvalid(al, drv) #validation loader\n",
    "\n",
    "const drtest = DataRunner(Xtest, ytest, [1]);\n",
    "const test = initvalid(al, drtest) #validation loader\n",
    "\n",
    "const nn = NNstruct(outGen=[256, 256, 10*110],\n",
    "postGen = [x-> @. x*1.5 + 2.5; x-> reshape(x, (110,10,:))],\n",
    "inVar = [110*10, 256, 256, 256]);\n",
    "const cs = CSstruct(resolution=10, \n",
    "nn_x=10, \n",
    "ny_nn=110, \n",
    "refsim=0.3364246930443735 + 0.1920021246559511im);\n",
    "const sd = SimulationDomain(cs)\n",
    "##setup MPI and random\n",
    "const comm = MPI.COMM_WORLD\n",
    "const model_color = MPI.Comm_rank(comm)%al.J\n",
    "const commModel = MPI.Comm_split(comm, model_color, 0)\n",
    "const isleader = MPI.Comm_rank(commModel) == 0\n",
    "const commLeader = MPI.Comm_split(comm, isleader, 0)\n",
    "debug && print(\"Comm rank=$(MPI.Comm_rank(comm)), commModel rank = $(MPI.Comm_rank(commModel)), commLeader rank = $(MPI.Comm_rank(commLeader))\\n\")\n",
    "Random.seed!(2134*(model_color+1)) #alter seed for different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dFE (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##training functionalities\n",
    "function train_distributed!(comm, commModel, commLeader, mloglik, m, loss, ps, loader, opt, validation_fes; logging=false)\n",
    "    for d in loader\n",
    "        train_loss, back = Zygote.pullback(() -> loss(commModel, mloglik, m, d...), ps)\n",
    "        gs = back(1.)\n",
    "        if debug && isleader\n",
    "            if isnan(train_loss)\n",
    "                @show (model_color, train_loss)\n",
    "            end\n",
    "        end\n",
    "        for x in ps\n",
    "            gs[x][:] .= sum_reduce(commModel, Float64.(gs[x][:]))\n",
    "            if debug && isleader\n",
    "                if any(isnan.(gs[x][:]))\n",
    "                    @show (model_color, train_loss)\n",
    "                    @show (length(x), length(findall(isnan,x)), length(findall(isnan,gs[x][:])))\n",
    "                end\n",
    "\n",
    "                if any(isinf.(gs[x][:]))\n",
    "                    @show (model_color, train_loss)\n",
    "                    @show (length(x), length(findall(isinf,x)), length(findall(isinf,gs[x][:])))\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if debug && isleader\n",
    "            for p_ in ps\n",
    "                if any(isnan.(p_))\n",
    "                    @show (model_color, \"before update\")\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        Flux.Optimise.update!(opt, ps, gs)\n",
    "        if debug && isleader\n",
    "            for p_ in ps\n",
    "                if any(isnan.(p_))\n",
    "                    @show (model_color, \"after update\")\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    logging && push!(validation_fes, dFE(comm, commModel, commLeader, m))\n",
    "end\n",
    "\n",
    "function dFE(comm, commModel, commLeader, m; valid=valid) \"\"\"dFE computes the FE using parallelization over the batch with MPI\"\"\" \n",
    "    evalsr = zeros(al.Nvalid)\n",
    "    evalsi = zeros(al.Nvalid)\n",
    "    FE = 0.\n",
    "    j=0\n",
    "    ys = Complex{Float64}[]\n",
    "    for (x, y) in valid\n",
    "        for i=1+MPI.Comm_rank(commModel):MPI.Comm_size(commModel):length(y)\n",
    "            rp, ip = m(x[:,i])\n",
    "            evalsr[j*length(y)+i] = rp\n",
    "            evalsi[j*length(y)+i] = ip\n",
    "        end\n",
    "        j+=1\n",
    "        push!(ys, y...)\n",
    "    end\n",
    "    evalsrModel = sum_reduce(commModel, evalsr)\n",
    "    evalsiModel = sum_reduce(commModel, evalsi)\n",
    "    evalsr = sum_reduce(commLeader, evalsrModel) / al.J\n",
    "    evalsi = sum_reduce(commLeader, evalsiModel) / al.J\n",
    "    if MPI.Comm_rank(comm) == 0\n",
    "        ŷ = @. evalsr + 1im * evalsi\n",
    "        FE = norm(ŷ - ys)/norm(ys)\n",
    "        @show FE\n",
    "    end\n",
    "    return FE\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kval = 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mLayer with Float32 parameters got Float64 input.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  The input will be converted, but any earlier layers may be very slow.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  layer = Dense(13 => 256, relu)  \u001b[90m# 3_584 parameters\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  summary(x) = \"13-element Vector{Float64}\"\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Flux C:\\Users\\XMhua\\.julia\\packages\\Flux\\CUn7U\\src\\layers\\stateless.jl:60\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE = 1.3602127809819944\n",
      "FE = 1.3335138053311935\n",
      "FE = 0.9220091263809985\n",
      "FE = 0.8535235023585223\n",
      "FE = 0.7912842866398608\n",
      "FE = 0.46707727421604744\n",
      "FE = 0.429364013652819\n",
      "FE = 0.34384514757418494\n",
      "FE = 0.3007922969038417\n",
      "FE = 0.31037220996540593\n",
      "353.417406 seconds (76.69 M allocations: 418.373 GiB, 5.54% gc time, 6.87% compilation time)\n"
     ]
    }
   ],
   "source": [
    "kval=2^7\n",
    "\n",
    "##define same AL parameters for all workers\n",
    "MPI.Barrier(comm)\n",
    "al1 = ALstruct(Ninit=256+8*kval, T=0);\n",
    "if MPI.Comm_rank(comm) == 0\n",
    "    @show kval\n",
    "end\n",
    "##ititialize DataRunner and DataSet\n",
    "dr = DataRunner(Xt, yt, [1]);\n",
    "ds = DataSet()\n",
    "validation_fes = []\n",
    "##initialize baseline\n",
    "(mgen, cw, mvar) = initmodel(nn)\n",
    "coarseinput(p) = begin \n",
    "    (coarsified, sd_freq) = Zygote.ignore() do\n",
    "        coarse_geom_func(p)\n",
    "    end\n",
    "    generated =dropdims(mgen(p), dims=3)\n",
    "    debug && isleader && any(isnan.(ϵcombine)) && writedlm(\"inputnan\", p) \n",
    "    debug && isleader && any(isnan.(ϵcombine)) && writedlm(\"mgennan\", mgen(p)) \n",
    "    debug && isleader && any(isnan.(ϵcombine)) && writedlm(\"mgennanparam\", ps)\n",
    "    debug && isleader && any(isnan.(ϵcombine)) && writedlm(\"errorcolor\", model_color)\n",
    "    w = NNlib.sigmoid.(cw*nn.multfact)\n",
    "    # w = max(0, min(1, cw))\n",
    "    ϵcombine = @. w * generated + (1-w) * coarsified\n",
    "    ϵsymmetric = ϵcombine#(ϵcombine .+ reverse(ϵcombine, dims=2))./2\n",
    "    return ϵsymmetric, sd_freq\n",
    "end\n",
    "m(p) = begin\n",
    "    ϵsymmetric, sd_freq = coarseinput(p)\n",
    "    return [realtransmissionSolver(ϵsymmetric, sd_freq = sd_freq); imagtransmissionSolver(ϵsymmetric, sd_freq = sd_freq)]\n",
    "end \n",
    "\n",
    "uq(p) = mvar(coarseinput(p)[1])\n",
    "\n",
    "mloglik(p) =  vcat(m(p), uq(p))\n",
    "ps = Flux.params(mgen, cw, mvar)\n",
    "# ps = Flux.params(mgen, mvar)\n",
    "loader = initloader(al1, dr, ds);\n",
    "opt = ADAM(al1.η)\n",
    "##train baseline\n",
    "if MPI.Comm_rank(comm)==0\n",
    "    @time for iepoch = 1:al1.ne \n",
    "        train_distributed!(comm, commModel, commLeader, mloglik, m, dNLL, ps, loader, opt, validation_fes, logging=true)\n",
    "    end\n",
    "else\n",
    "    for iepoch = 1:al1.ne \n",
    "        train_distributed!(comm, commModel, commLeader, mloglik, m, dNLL, ps, loader, opt, validation_fes, logging=true)\n",
    "    end\n",
    "end\n",
    "##active learning loop\n",
    "for t=1:al1.T\n",
    "    MPI.Comm_rank(comm) == 0 && @show t\n",
    "    loader= getloader(al1, dr, ds, X->varfilter(mloglik, X))\n",
    "    if MPI.Comm_rank(comm)==0 \n",
    "        @time for iepoch = 1:al1.ne \n",
    "            train_distributed!(comm, commModel, commLeader, mloglik, m, dNLL, ps, loader, opt, validation_fes, logging=true)\n",
    "        end\n",
    "    else\n",
    "        for iepoch = 1:al1.ne \n",
    "            train_distributed!(comm, commModel, commLeader, mloglik, m, dNLL, ps, loader, opt, validation_fes, logging=true)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# ##save models and validation FEs\n",
    "# name = \"PEDS10_example\"\n",
    "# if isleader\n",
    "#     BSON.@save \"$(name)_K$(kval)_mgen$(model_color).bson\" mgen\n",
    "#     BSON.@save \"$(name)_K$(kval)_cw$(model_color).bson\" cw\n",
    "#     BSON.@save \"$(name)_K$(kval)_mvar$(model_color).bson\" mvar\n",
    "# end\n",
    "# if MPI.Comm_rank(comm) == 0\n",
    "#     writedlm(\"$(name)_K$(kval)_validation_fes.csv\", validation_fes, ',')\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE = 0.318472620296603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.318472620296603"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dFE(comm, commModel, commLeader, m, valid=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEDS result\n",
    "\n",
    "The fractional error on the test set is 0.278."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kval = 128\n",
      "FE = 0.8060907234972654\n",
      "FE = 0.7383732494364024\n",
      "FE = 0.6204775997590223\n",
      "FE = 0.5923675026062127\n",
      "FE = 0.5361577078931435\n",
      "FE = 0.539619721796218\n",
      "FE = 0.5302943719601326\n",
      "FE = 0.5456588695261273\n",
      "FE = 0.49424089719077735\n",
      "FE = 0.4902350352298319\n",
      " 22.341325 seconds (9.78 M allocations: 70.384 GiB, 24.18% gc time, 6.42% compilation time: 19% of which was recompilation)\n"
     ]
    }
   ],
   "source": [
    "##define same AL parameters for all workers\n",
    "MPI.Barrier(comm)\n",
    "al1 = ALstruct(Ninit=256+8*kval, T=0);\n",
    "\n",
    "if MPI.Comm_rank(comm) == 0\n",
    "    @show kval\n",
    "end\n",
    "##ititialize DataRunner and DataSet\n",
    "dr = DataRunner(Xt, yt, [1]);\n",
    "ds = DataSet()\n",
    "validation_fes = []\n",
    "##initialize baseline\n",
    "(mgen, pred, mvar) = initbase(nn)\n",
    "mloglik(p) =  vcat(pred(mgen(p)), mvar(mgen(p)))\n",
    "m(p) = pred(mgen(p))\n",
    "ps = Flux.params(mgen, pred, mvar)\n",
    "loader = initloader(al1, dr, ds);\n",
    "opt = ADAM(al1.η)\n",
    "##train baseline\n",
    "if MPI.Comm_rank(comm)==0\n",
    "    @time for iepoch = 1:al1.ne \n",
    "        train_distributed!(comm, commModel, commLeader, mloglik, m, dNLL, ps, loader, opt, validation_fes, logging=true)\n",
    "    end\n",
    "else\n",
    "    for iepoch = 1:al1.ne \n",
    "        train_distributed!(comm, commModel, commLeader, mloglik, m, dNLL, ps, loader, opt, validation_fes, logging=true)\n",
    "    end\n",
    "end\n",
    "##active learning loop\n",
    "for t=1:al1.T\n",
    "    MPI.Comm_rank(comm) == 0 && @show t\n",
    "    loader= getloader(al1, dr, ds, X->varfilter(mloglik, X)) \n",
    "    if MPI.Comm_rank(comm)==0 \n",
    "        @time for iepoch = 1:al1.ne \n",
    "            train_distributed!(comm, commModel, commLeader, mloglik, m, dNLL, ps, loader, opt, validation_fes, logging=true)\n",
    "        end\n",
    "    else\n",
    "        for iepoch = 1:al1.ne \n",
    "            train_distributed!(comm, commModel, commLeader, mloglik, m, dNLL, ps, loader, opt, validation_fes, logging=true)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# ##save models and validation FEs\n",
    "# name = \"baseline10_noal_example\"\n",
    "# if isleader\n",
    "#     BSON.@save \"$(name)_K$(kval)_mgen$(model_color).bson\" mgen\n",
    "#     BSON.@save \"$(name)_K$(kval)_pred$(model_color).bson\" pred\n",
    "#     BSON.@save \"$(name)_K$(kval)_mvar$(model_color).bson\" mvar\n",
    "# end\n",
    "# if MPI.Comm_rank(comm) == 0\n",
    "#     writedlm(\"$(name)_K$(kval)_validation_fes.csv\", validation_fes, ',')\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE = 0.5027021042100664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5027021042100664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dFE(comm, commModel, commLeader, m, valid=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline result \n",
    "\n",
    "The fractional error on the test set is 0.541."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall result\n",
    "\n",
    "With about 1000 data points, a single model PEDS model leads to a 1.9x improvement compared to the NN-only baseline. For the Maxwell surrogate, in contrast to diffusion and reaction-diffusion equations, more points are needed to achieve an accuracy comparable to fabrication error (< 5%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
